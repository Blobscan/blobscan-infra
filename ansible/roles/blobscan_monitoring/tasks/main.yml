- name: Install alloy
  ansible.builtin.include_role:
    name: grafana.grafana.alloy
  vars:
    config: |
      prometheus.remote_write "prom" {
        endpoint {
          url = "{{ prometheus_url }}"

          basic_auth {
            username = "{{ metrics_username }}"
            password = "{{ grafana_cloud_api_key }}"
          }

          queue_config { }
          metadata_config { }
        }
      }

      discovery.relabel "blobscan_api" {
        targets = [
          { __address__ = "localhost:3001" },
        ]

        rule {
          target_label = "instance"
          replacement  = constants.hostname
        }

        rule {
          target_label = "environment"
          replacement  = "{{ env }}"
        }

        rule {
          target_label = "network"
          replacement  = "{{ network }}"
        }
      }

      prometheus.scrape "blobscan_api" {
        targets    = discovery.relabel.blobscan_api.output
        forward_to = [prometheus.relabel.blobscan_api.receiver]
        job_name   = "blobscan-api"
      }

      prometheus.relabel "blobscan_api" {
        forward_to = [prometheus.remote_write.prom.receiver]
      }

      discovery.relabel "blobscan_queue" {
        targets = [
          { __address__ = "localhost:3000" },
        ]

        rule {
          target_label = "instance"
          replacement  = constants.hostname
        }

        rule {
          target_label = "environment"
          replacement  = "{{ env }}"
        }

        rule {
          target_label = "network"
          replacement  = "{{ network }}"
        }
      }

      prometheus.scrape "blobscan_queue" {
        targets    = discovery.relabel.blobscan_queue.output
        forward_to = [prometheus.relabel.blobscan_queue.receiver]
        job_name   = "blobscan-queue"
      }

      prometheus.relabel "blobscan_queue" {
        forward_to = [prometheus.remote_write.prom.receiver]
      }

      discovery.docker "integrations_docker" {
        host             = "unix:///run/docker.sock"
        refresh_interval = "5s"
      }

      discovery.relabel "integrations_docker" {
        targets         = discovery.docker.integrations_docker.targets

        rule {
          source_labels = ["__meta_docker_container_id"]
          target_label  = "job"
          replacement   = "integrations/docker"
        }

        rule {
          source_labels = ["__meta_docker_container_id"]
          target_label  = "instance"
          replacement   = "localhost:9090"
        }

        rule {
          source_labels = ["__meta_docker_container_name"]
          regex         = "/(.*)"
          target_label  = "container"
        }

        rule {
          source_labels = ["__meta_docker_container_log_stream"]
          target_label  = "stream"
        }

        rule {
          target_label = "environment"
          replacement  = "{{ env }}"
        }

        rule {
          target_label = "network"
          replacement  = "{{ network }}"
        }
      }

      loki.write "logs_integrations" {
        endpoint {
          url = "{{ loki_url }}"
        }

        external_labels = {}
      }

      prometheus.exporter.blackbox "integrations_blackbox" {
        config = "modules:\n  http_2xx:\n    prober: http\n    timeout: 5s\n"

        target {
          name    = "blobscan-api"
          address = "https://api.{{ domain }}"
          module  = "http_2xx"
          labels = {
            "network" = "{{ network }}",
          }
        }

        target {
          name    = "blobscan-web"
          address = "https://{{ domain }}"
          module  = "http_2xx"
          labels = {
            "network" = "{{ network }}",
          }
        }
      }

      discovery.relabel "integrations_blackbox" {
        targets = prometheus.exporter.blackbox.integrations_blackbox.targets

        rule {
          target_label = "instance"
          replacement  = constants.hostname
        }

        rule {
          target_label = "environment"
          replacement  = "{{ env }}"
        }

        rule {
          target_label = "network"
          replacement  = "{{ network }}"
        }

        rule {
          target_label = "job"
          replacement  = "integrations/blackbox"
        }
      }

      prometheus.scrape "integrations_blackbox" {
        targets    = discovery.relabel.integrations_blackbox.output
        forward_to = [prometheus.remote_write.prom.receiver]
        job_name   = "integrations/blackbox"
      }

      prometheus.exporter.cadvisor "integrations_cadvisor" {
        docker_only = true
      }

      discovery.relabel "integrations_cadvisor" {
        targets = prometheus.exporter.cadvisor.integrations_cadvisor.targets

        rule {
          source_labels = ["__name__"]
          regex         = "(container_last_seen|container_cpu_usage_seconds_total|container_spec_memory_reservation_limit_bytes|container_memory_usage_bytes|container_network_receive_bytes_total|container_network_transmit_bytes_total|container_network_tcp_usage_total|container_fs_usage_bytes|container_fs_limit_bytes|container_fs_inodes_free|container_fs_inodes_total)"
          action        = "keep"
        }

        rule {
          target_label = "job"
          replacement  = "integrations/cadvisor"
        }

        rule {
          target_label = "instance"
          replacement  = constants.hostname
        }

        rule {
          target_label = "environment"
          replacement  = "{{ env }}"
        }

        rule {
          target_label = "network"
          replacement  = "{{ network }}"
        }
      }

      prometheus.scrape "integrations_cadvisor" {
        targets    = discovery.relabel.integrations_cadvisor.output
        forward_to = [prometheus.relabel.integrations_cadvisor.receiver]
        job_name   = "integrations/cadvisor"
      }

      prometheus.relabel "integrations_cadvisor" {
        forward_to = [prometheus.remote_write.prom.receiver]
      }

      prometheus.exporter.unix "integrations_node_exporter" { }

      discovery.relabel "integrations_node_exporter" {
        targets = prometheus.exporter.unix.integrations_node_exporter.targets

        rule {
          source_labels = ["__name__"]
          regex         = "(prometheus_fanout_latency_bucket|prometheus_target_sync_length_seconds)"
          action        = "drop"
        }

        rule {
          target_label = "job"
          replacement  = "integrations/node_exporter"
        }

        rule {
          target_label = "instance"
          replacement  = constants.hostname
        }

        rule {
          target_label = "environment"
          replacement  = "{{ env }}"
        }

        rule {
          target_label = "network"
          replacement  = "{{ network }}"
        }
      }

      prometheus.scrape "integrations_node_exporter" {
        targets    = discovery.relabel.integrations_node_exporter.output
        forward_to = [prometheus.remote_write.prom.receiver]
        job_name   = "integrations/node_exporter"
      }

      otelcol.receiver.jaeger "default" {
        protocols {
          thrift_http { }
        }

        output {
          traces = [otelcol.exporter.otlp.default_0.input]
        }
      }

      otelcol.receiver.otlp "default" {
        grpc {
          include_metadata = true
        }

        http {
          include_metadata = true
        }

        output {
          metrics = []
          logs    = []
          traces  = [otelcol.exporter.otlp.default_0.input]
        }
      }

      otelcol.exporter.otlp "default_0" {
        retry_on_failure {
          max_elapsed_time = "1m0s"
        }

        client {
          endpoint = "{{ tempo_url }}"
          headers  = {
            authorization = "Basic {{ tempo_basic_auth }}",
          }
        }
      }

#     loki.source.docker "integrations_docker" {
#       host             = "unix:///run/docker.sock"
#       targets          = discovery.docker.integrations_docker.targets
#       forward_to       = [loki.write.logs_integrations.receiver]
#       relabel_rules    = discovery.relabel.integrations_docker.rules
#     }

# TODO: Add more exporters
# redis_exporter:
# postgres_exporter:
# github_exporter:
# gcp_exporter:

- name: Add alloy user to docker group
  user:
    name: alloy
    groups:
      - docker

- name: Run bullmq exporter
  community.docker.docker_container:
    name: "bullmq-prometheus"
    image: "blossomlabs/bullmq-prometheus"
    image_name_mismatch: recreate
    state: started
    restart_policy: always
    ports: "3000:3000"
    pull: "always"
    env:
      REDIS_URI: "{{ redis_uri }}"
      REDIS_DB: "{{ redis_db }}:{{ network }}-{{ env }}"
